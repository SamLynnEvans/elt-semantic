{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda1414-1b81-43f4-ac50-11507de2489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "if (ENV := os.getenv(\"ENV\")) is None:\n",
    "    raise RuntimeError(\"ENV must be set\")\n",
    "if (DUCKDB_PATH := os.getenv(\"DUCKDB_PATH\")) is None:\n",
    "    raise RuntimeError(\"DUCKDB_PATH must be set\")\n",
    "if (CHROMA_DB_DIR := os.getenv(\"CHROMA_DB_DIR\")) is None:\n",
    "    raise RuntimeError(\"CHROMA_DB_PATH must be set\")\n",
    "if (GEMINI_API_KEY := os.getenv(\"GEMINI_API_KEY\")) is None:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY must be set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58494731-e044-4ef7-9af3-96468a1e1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import date\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class RagRecord(BaseModel):\n",
    "    doc_id: int\n",
    "    document_title: str\n",
    "    last_modified: date\n",
    "    document_text: str\n",
    "    ticket_id: Optional[str]\n",
    "    priority: Optional[str]\n",
    "    department: Optional[str]\n",
    "    resolution_summary: Optional[str]\n",
    "    rag_chunk: str\n",
    "\n",
    "    def to_metadata(self) -> \"ChunkMetadata\":\n",
    "        return ChunkMetadata(\n",
    "            **self.model_dump(include=ChunkMetadata.model_fields.keys())\n",
    "        )\n",
    "\n",
    "\n",
    "class ChunkMetadata(BaseModel):\n",
    "    doc_id: int\n",
    "    document_title: str\n",
    "    last_modified: date\n",
    "    ticket_id: Optional[str]\n",
    "    priority: Optional[str]\n",
    "    department: Optional[str]\n",
    "    resolution_summary: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9bb15-d00d-45c4-89a4-7cad1275947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "def stream_rag_records(db_path: str, batch_size: int=10) -> list[RagRecord]:\n",
    "    \"\"\"\n",
    "    Stream rows from the docs_for_rag table in DuckDB in fixed-size batches.\n",
    "\n",
    "    The query cursor fetches up to `batch_size` rows at a time using `fetchmany`,\n",
    "    which avoids loading the entire table into memory. Each batch is converted\n",
    "    into a list of RagRecord objects and yielded to the caller.\n",
    "\n",
    "    The `while True` loop terminates naturally when DuckDB returns an empty list,\n",
    "    signalling that all rows have been consumed.\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"SELECT * FROM {ENV}_marts.docs_for_rag\"\n",
    "    con = duckdb.connect(db_path, read_only=True)\n",
    "    result = con.execute(sql)\n",
    "    col_names = [c[0] for c in result.description]\n",
    "\n",
    "    while True:\n",
    "        rows = result.fetchmany(batch_size)\n",
    "        if not rows:\n",
    "            break\n",
    "\n",
    "        yield [RagRecord(**dict(zip(col_names, row))) for row in rows]\n",
    "\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def embed_texts(texts: list[str]) -> list[list[float]]:\n",
    "    \"\"\"Embed a batch of strings using Gemini embeddings.\"\"\"\n",
    "    \n",
    "    response = genai.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        content=texts\n",
    "    )\n",
    "    \n",
    "    return response['embedding']\n",
    "\n",
    "\n",
    "def chunk_text(text: str, max_words=500) -> list[str]:\n",
    "    \"\"\"\n",
    "    Simple word-based chunker. Splits text into chunks of up to `max_words`\n",
    "    while preserving word boundaries. Suitable for small datasets and demo RAG.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        chunk_words = words[i : i + max_words]\n",
    "        chunks.append(\" \".join(chunk_words))\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f5eb40b562774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "\n",
    "client = chromadb.PersistentClient(path=os.getenv(\"CHROMA_DB_DIR\"))\n",
    "\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"policy_rag\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    ")\n",
    "\n",
    "\n",
    "for records in stream_rag_records(DUCKDB_PATH):\n",
    "    all_chunks = []\n",
    "    all_ids = []\n",
    "    all_metadatas = []\n",
    "\n",
    "    for rec in records:\n",
    "        chunks = chunk_text(rec.rag_chunk)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            meta = rec.to_metadata().model_dump(mode=\"json\")\n",
    "            meta[\"num_chunks\"] = len(chunks)\n",
    "            meta[\"chunk_index\"] = i\n",
    "            all_chunks.append(chunk)\n",
    "            all_ids.append(f\"{rec.doc_id}_{rec.ticket_id}_{i}\")\n",
    "            all_metadatas.append(meta)\n",
    "            \n",
    "    embeddings = embed_texts(all_chunks) \n",
    "    \n",
    "    collection.add(\n",
    "                ids=all_ids,\n",
    "                embeddings=embeddings,\n",
    "                documents=all_chunks,\n",
    "                metadatas=all_metadatas\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d978db-aa9c-4bb1-9cca-6c5b60195b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that number of records pulled from database equals number of entries in chroma.\n",
    "# We'd expect this not to match if there were larger chunks, but in the provided demo data it should be the same\n",
    "\n",
    "con = duckdb.connect(DUCKDB_PATH, read_only=True)\n",
    "assert len(con.query(f\"SELECT * FROM {ENV}_marts.docs_for_rag\").fetchall()) == collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f2debf74fcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metadata parsing/upload: Roll up data in mart and collection to check they are the same\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def duckdb_rollup(db_path=\"/app/database/mydb.duckdb\"):\n",
    "    con = duckdb.connect(db_path, read_only=True)\n",
    "    df = con.execute(\n",
    "        f\"\"\"\n",
    "        SELECT department, COUNT(*) AS duckdb_count\n",
    "        FROM {ENV}_marts.docs_for_rag\n",
    "        GROUP BY department\n",
    "        ORDER BY duckdb_count DESC\n",
    "        \"\"\"\n",
    "    ).df()\n",
    "    con.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def chroma_rollup(collection, batch_size=500):\n",
    "    dept_counter = Counter()\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        res = collection.get(\n",
    "            include=[\"metadatas\"],\n",
    "            limit=batch_size,\n",
    "            offset=offset\n",
    "        )\n",
    "\n",
    "        metadatas = res.get(\"metadatas\", [])\n",
    "        if not metadatas:\n",
    "            break\n",
    "\n",
    "        for m in metadatas:\n",
    "            dept = m.get(\"department\")\n",
    "            if dept is not None:\n",
    "                dept_counter[dept] += 1\n",
    "\n",
    "        offset += batch_size\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [{\"department\": d, \"chroma_count\": c} for d, c in dept_counter.items()]\n",
    "    ).sort_values(\"chroma_count\", ascending=False)\n",
    "    return df\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "duckdb_df = duckdb_rollup()\n",
    "chroma_df = chroma_rollup(collection)\n",
    "\n",
    "\n",
    "html = f\"\"\"\n",
    "<div style=\"display:flex; gap:40px;\">\n",
    "    <div>{duckdb_df.to_html(index=False)}</div>\n",
    "    <div>{chroma_df.to_html(index=False)}</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d2e22-b0ec-4ae7-bfff-71d20700ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function to test semantic search\n",
    "\n",
    "def search(query: str, top_k: int = 1, where: dict | None = None) -> list[dict]:\n",
    "    embedding = embed_texts([query])[0]\n",
    "\n",
    "    \n",
    "    result = collection.query(\n",
    "        query_embeddings=[embedding],\n",
    "        n_results=top_k,\n",
    "        where=where\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"documents\": result[\"documents\"][0],\n",
    "        \"metadatas\": result[\"metadatas\"][0],\n",
    "        \"distances\": result[\"distances\"][0],\n",
    "        \"ids\": result[\"ids\"][0],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd984cf4-b0c2-46d1-be18-acd63b0a7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate unique values for filtering\n",
    "\n",
    "con.query(f\"select distinct department from {ENV}_marts.docs_for_rag\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794afa10951b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"hotel policy\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b297c95-babb-4fff-a026-b1633651d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"how much monthly paid time off do employees get\", 1, {\"department\": \"HR\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
